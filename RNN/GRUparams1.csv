fold,batch_size,epochs,learning_rate,activation,dropout_rate,optimizer,num_units,num_layers,lambda1,lambda2
0,60,10,7.91507439765624e-05,selu,0.22291637642679563,Adam,97,2,0.21429345433755265,0.6207107783590824
1,120,30,4.061136676690667e-05,relu,0.128034161380662,Adam,145,1,0.45146920149261616,0.261375361868317
2,120,30,4.061136676690667e-05,relu,0.128034161380662,Adam,145,1,0.45146920149261616,0.261375361868317
3,120,30,4.061136676690667e-05,relu,0.128034161380662,Adam,145,1,0.45146920149261616,0.261375361868317
4,120,30,4.061136676690667e-05,relu,0.128034161380662,Adam,145,1,0.45146920149261616,0.261375361868317
5,120,30,4.061136676690667e-05,relu,0.128034161380662,Adam,145,1,0.45146920149261616,0.261375361868317
